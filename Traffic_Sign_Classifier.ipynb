{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# Set Directories\n",
    "\n",
    "training_file = \"./data/train.p\"\n",
    "validation_file= \"./data/valid.p\"\n",
    "testing_file = \"./data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of validation examples\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# Image Shape\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# Number of Classes\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a random sample of the dataset with its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "\n",
    "plt.imshow(X_train[index])\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## CovNet Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images have been converted to grayscale for helping the network learn faster. The data has also been mean normalized and scaled from 0 to 1 for improving the optimizer performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale training and validation sets\n",
    "\n",
    "train_grays = np.mean(X_train, axis = -1)\n",
    "valid_grays = np.mean(X_valid, axis = -1)\n",
    "\n",
    "# Reshape grayscaled images into appropriate size for inputting into the CovNet\n",
    "\n",
    "train_grays = np.reshape(train_grays, [n_train, train_grays[0].shape[0], train_grays[0].shape[1], 1])\n",
    "valid_grays = np.reshape(valid_grays, [n_valid, train_grays[0].shape[0], train_grays[0].shape[1], 1])\n",
    "\n",
    "# Mean normalize and scale validation and test sets\n",
    "\n",
    "X_train = np.divide(np.subtract(train_grays, np.mean(train_grays)), np.mean(train_grays))\n",
    "X_valid = np.divide(np.subtract(valid_grays, np.mean(valid_grays)), np.mean(valid_grays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Softwares\\Installed\\miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified LeNet-5 Architecture\n",
    "\n",
    "Modifications:\n",
    "1. Removed all max pooling layers and replaced with dropouts to prevent overfitting without loss of data.\n",
    "2. Added additional convolution layer to reduce input image size and increase depth. This was necessary as there is no max pooling layer in the network.\n",
    "3. Added additional fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet(x, keep_prob):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    ## weight = tf.Variable(tf.truncated_normal([filter_height, filter_width, color_channels, k_output]))\n",
    "    ## bias = tf.Variable(tf.zeros(k_output))\n",
    "    \n",
    "    # Convolutional Layer 1. Input = 32x32x1. Output = 28x28x12.\n",
    "    \n",
    "    wc1 = tf.Variable(tf.truncated_normal([5, 5, 1, 12], mu, sigma))\n",
    "    bc1 = tf.Variable(tf.zeros(12))\n",
    "    conv1 = tf.nn.conv2d(x, wc1, strides=[1, 1, 1, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, bc1)\n",
    "\n",
    "    # Layer 1 Activation and Dropout\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "    # Convolutional Layer 2. Input = 28x28x12. Output = 20x20x32.\n",
    "    \n",
    "    wc2 = tf.Variable(tf.truncated_normal([9, 9, 12, 32], mu, sigma))\n",
    "    bc2 = tf.Variable(tf.zeros(32))\n",
    "    conv2 = tf.nn.conv2d(conv1, wc2, strides=[1, 1, 1, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, bc2)\n",
    "    \n",
    "    # Layer 2 Activation and Dropout\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    \n",
    "    # Convolutional Layer 3. Input = 20x20x32. Output = 10x10x64.\n",
    "    \n",
    "    wc3 = tf.Variable(tf.truncated_normal([11, 11, 32, 64], mu, sigma))\n",
    "    bc3 = tf.Variable(tf.zeros(64))\n",
    "    conv3 = tf.nn.conv2d(conv2, wc3, strides=[1, 1, 1, 1], padding = 'VALID')\n",
    "    conv3 = tf.nn.bias_add(conv3, bc3)\n",
    "    \n",
    "    # Layer 3 Activation and Dropout\n",
    "    \n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    \n",
    "    # Flatten. Input = 10x10x64. Output = 6400.\n",
    "    \n",
    "    fc1 = tf.layers.flatten(conv3)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 6400. Output = 1600.\n",
    "    \n",
    "    wd1 = tf.Variable(tf.truncated_normal((6400, 1600), mu, sigma))\n",
    "    bd1 = tf.Variable(tf.zeros(1600))\n",
    "    fc1 = tf.add(tf.matmul(fc1, wd1), bd1)  \n",
    "    \n",
    "    # Layer 3 Activation and Dropout\n",
    "    \n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 1600. Output = 400.\n",
    "    \n",
    "    wd2 = tf.Variable(tf.truncated_normal((1600, 400), mu, sigma))\n",
    "    bd2 = tf.Variable(tf.zeros(400))\n",
    "    fc2 = tf.add(tf.matmul(fc1, wd2), bd2)\n",
    "    \n",
    "    # Layer 4 Activation and Dropout\n",
    "    \n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 400. Output = 100.\n",
    "    \n",
    "    wd3 = tf.Variable(tf.truncated_normal((400, 100), mu, sigma))\n",
    "    bd3 = tf.Variable(tf.zeros(100))\n",
    "    fc3 = tf.add(tf.matmul(fc2, wd3), bd3)\n",
    "    \n",
    "    # Layer 5 Activation and Dropout\n",
    "    \n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    fc3 = tf.nn.dropout(fc3, keep_prob)\n",
    "    \n",
    "    # Layer 6: Fully Connected. Input = 100. Output = 43.\n",
    "    \n",
    "    wd4 = tf.Variable(tf.truncated_normal((100, 43), mu, sigma))\n",
    "    bd4 = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.add(tf.matmul(fc3, wd4), bd4)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Tensorflow Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions: Optimizer, Loss Function and Training Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-22d5a18bd003>:19: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-7-22d5a18bd003>:47: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "WARNING:tensorflow:From D:\\Softwares\\Installed\\miniconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-e9ddbc743ebb>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = LeNet(x, keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training, Validation and Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.266\n",
      "Training Accuracy = 0.314\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.800\n",
      "Training Accuracy = 0.840\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.910\n",
      "Training Accuracy = 0.945\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.938\n",
      "Training Accuracy = 0.971\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.954\n",
      "Training Accuracy = 0.982\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.961\n",
      "Training Accuracy = 0.986\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.968\n",
      "Training Accuracy = 0.992\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.967\n",
      "Training Accuracy = 0.993\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.968\n",
      "Training Accuracy = 0.994\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.968\n",
      "Training Accuracy = 0.995\n",
      "\n",
      "Test Accuracy = 0.942\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.75})\n",
    "\n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        training_accuracy = evaluate(X_train, y_train)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print(\"Training Accuracy = {:.3f}\".format(training_accuracy))\n",
    "        print()\n",
    "      \n",
    "    # Run model on test set, once finalized. Uncomment following code to test.\n",
    "    test_grays = np.mean(X_test, axis = -1)\n",
    "    test_grays = np.reshape(test_grays, [n_test, test_grays[0].shape[0], test_grays[0].shape[1], 1])\n",
    "    X_test = np.divide(np.subtract(test_grays, np.mean(test_grays)), np.mean(test_grays))\n",
    "    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy)) \n",
    "    \n",
    "    # Save Model\n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Testing on New Images\n",
    "\n",
    "6 images of German Traffic Signs were downloaded from Google Images and were labelled manually. The following code runs the network on these images and the classification predictions have been documented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Extract images \n",
    "filelist = glob.glob('images/*.png')\n",
    "\n",
    "new_images = []\n",
    "img_size = [32, 32, 3]\n",
    "for file in filelist:\n",
    "    image = Image.open(file)\n",
    "    image = image.resize((32,32), Image.ANTIALIAS)\n",
    "    new_image = np.array(image.getdata(), np.uint8).reshape(img_size[0], img_size[1], img_size[2])\n",
    "    new_images.append(new_image)\n",
    "\n",
    "# Label images based on 'signnames.csv'\n",
    "y_new = np.array([38, 25, 17, 18, 28, 30], np.uint8)\n",
    "\n",
    "# Display images\n",
    "index = 2\n",
    "plt.imshow(new_images[index])\n",
    "print(y_new[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert New Images to Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e3aef38160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_grays = np.mean(new_images, axis = -1)\n",
    "new_grays = np.reshape(new_grays, [len(new_images), new_grays[0].shape[0], new_grays[0].shape[1], 1])\n",
    "X_new = np.divide(np.subtract(new_grays, np.mean(new_grays)), np.mean(new_grays))\n",
    "\n",
    "plt.imshow(X_new[index, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_operation = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n"
     ]
    }
   ],
   "source": [
    "## Load Saved Model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, './lenet')\n",
    "    prediction = sess.run(prediction_operation, feed_dict={x: X_new, keep_prob: 1.0})\n",
    "    new_accuracy = evaluate(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance on New Images\n",
    "\n",
    "The accuracy of the model on the new images is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "print(new_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Softmax Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopKV2(values=array([[1.0000000e+00, 2.0526193e-14, 2.4291518e-16, 1.4536758e-16,\n",
      "        1.2742560e-16],\n",
      "       [9.9999976e-01, 2.0735625e-07, 2.7036421e-08, 9.8888266e-09,\n",
      "        4.7915929e-09],\n",
      "       [1.0000000e+00, 1.1330560e-18, 3.3650832e-20, 1.5862990e-21,\n",
      "        4.8321656e-22],\n",
      "       [9.9999559e-01, 4.3708465e-06, 2.4847937e-08, 2.1150043e-08,\n",
      "        1.7308187e-08],\n",
      "       [9.9971980e-01, 2.4624236e-04, 1.3201782e-05, 5.0615731e-06,\n",
      "        4.2776933e-06],\n",
      "       [6.8966967e-01, 1.2849243e-01, 1.2607929e-01, 3.2432131e-02,\n",
      "        2.1688623e-02]], dtype=float32), indices=array([[38, 14, 13, 25, 15],\n",
      "       [25, 20, 12, 31, 17],\n",
      "       [17,  8, 14,  0,  3],\n",
      "       [18, 26, 27, 11,  8],\n",
      "       [28, 20, 29, 30, 11],\n",
      "       [42, 20, 30, 25, 11]]))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    top5 = sess.run(tf.nn.top_k(tf.constant(prediction), k=5))\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 (Optional): Visualize the Neural Network's State with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
